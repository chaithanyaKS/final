{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport math\nimport numpy as np\nimport pandas as pd\n\nimport scikitplot\nimport seaborn as sns\nfrom matplotlib import pyplot\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nimport tensorflow as tf\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Flatten, Dense, GlobalAvgPool2D, GlobalMaxPool2D\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.mobilenet import MobileNet\nfrom tensorflow.keras.utils import plot_model\n\nfrom keras.utils import np_utils","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-07-03T09:50:13.871163Z","iopub.execute_input":"2021-07-03T09:50:13.871483Z","iopub.status.idle":"2021-07-03T09:50:21.975115Z","shell.execute_reply.started":"2021-07-03T09:50:13.871448Z","shell.execute_reply":"2021-07-03T09:50:21.974206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INPUT_PATH = \"../input/fer13-cleaned-dataset/\"","metadata":{"execution":{"iopub.status.busy":"2021-07-03T09:50:21.980136Z","iopub.execute_input":"2021-07-03T09:50:21.982683Z","iopub.status.idle":"2021-07-03T09:50:21.989677Z","shell.execute_reply.started":"2021-07-03T09:50:21.982633Z","shell.execute_reply":"2021-07-03T09:50:21.988465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_images = 0\nfor dir_ in os.listdir(INPUT_PATH):\n    count = 0\n    for f in os.listdir(INPUT_PATH + dir_ + \"/\"):\n        count += 1\n        total_images += 1\n    print(f\"{dir_} has {count} number of images\")\n    \nprint(f\"\\ntotal images are {total_images}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-03T09:50:21.99533Z","iopub.execute_input":"2021-07-03T09:50:21.995844Z","iopub.status.idle":"2021-07-03T09:50:22.536845Z","shell.execute_reply.started":"2021-07-03T09:50:21.995805Z","shell.execute_reply":"2021-07-03T09:50:22.536076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TOP_EMOTIONS = [\"fear\", \"Happy\", \"Neutral\", \"Angry\"]\ntotal_images -= 380\ntotal_images","metadata":{"execution":{"iopub.status.busy":"2021-07-03T09:50:22.540987Z","iopub.execute_input":"2021-07-03T09:50:22.543178Z","iopub.status.idle":"2021-07-03T09:50:22.555148Z","shell.execute_reply.started":"2021-07-03T09:50:22.543135Z","shell.execute_reply":"2021-07-03T09:50:22.554291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-07-03T09:02:03.853297Z","iopub.execute_input":"2021-07-03T09:02:03.853615Z","iopub.status.idle":"2021-07-03T09:02:03.858264Z","shell.execute_reply.started":"2021-07-03T09:02:03.853583Z","shell.execute_reply":"2021-07-03T09:02:03.857226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_size = 48\nimg_arr = np.empty(shape=(total_images, img_size, img_size,3))\nimg_label = np.empty(shape=(total_images))\nlabel_to_text = {}\n\ni = 0\ne = 0\nfor dir_ in os.listdir(INPUT_PATH):\n    if dir_ in TOP_EMOTIONS:\n        label_to_text[e] = dir_\n        for f in os.listdir(INPUT_PATH + dir_ + \"/\"):\n            img_arr[i] = cv2.imread(INPUT_PATH + dir_ + \"/\" + f)\n            img_label[i] = e\n            i += 1\n        print(f\"loaded all {dir_} images to numpy arrays\")\n        e += 1\n\nimg_arr.shape, img_label","metadata":{"execution":{"iopub.status.busy":"2021-07-03T09:51:04.850055Z","iopub.execute_input":"2021-07-03T09:51:04.850344Z","iopub.status.idle":"2021-07-03T09:51:57.993552Z","shell.execute_reply.started":"2021-07-03T09:51:04.850314Z","shell.execute_reply":"2021-07-03T09:51:57.992714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_to_text","metadata":{"execution":{"iopub.status.busy":"2021-07-03T09:51:57.998199Z","iopub.execute_input":"2021-07-03T09:51:58.00406Z","iopub.status.idle":"2021-07-03T09:51:58.017828Z","shell.execute_reply.started":"2021-07-03T09:51:58.004019Z","shell.execute_reply":"2021-07-03T09:51:58.016977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = pyplot.figure(1, (8,8))\n\nidx = 0\nfor k in label_to_text:\n    sample_indices = np.random.choice(np.where(img_label==k)[0], size=4, replace=False)\n    sample_images = img_arr[sample_indices]\n    for img in sample_images:\n        idx += 1\n        ax = pyplot.subplot(4,4,idx)\n        ax.imshow(img[:,:,0], cmap='gray')\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_title(label_to_text[k])\n        pyplot.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T09:51:58.02092Z","iopub.execute_input":"2021-07-03T09:51:58.024132Z","iopub.status.idle":"2021-07-03T09:52:00.064229Z","shell.execute_reply.started":"2021-07-03T09:51:58.024099Z","shell.execute_reply":"2021-07-03T09:52:00.063392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_label = np_utils.to_categorical(img_label)\nimg_label.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-03T09:52:00.065391Z","iopub.execute_input":"2021-07-03T09:52:00.065658Z","iopub.status.idle":"2021-07-03T09:52:00.072468Z","shell.execute_reply.started":"2021-07-03T09:52:00.065626Z","shell.execute_reply":"2021-07-03T09:52:00.071683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`Splitting the data into training and validation set.`","metadata":{}},{"cell_type":"code","source":"img_arr.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-03T09:52:00.075313Z","iopub.execute_input":"2021-07-03T09:52:00.075826Z","iopub.status.idle":"2021-07-03T09:52:00.081772Z","shell.execute_reply.started":"2021-07-03T09:52:00.075786Z","shell.execute_reply":"2021-07-03T09:52:00.080901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_arr = img_arr / 255.","metadata":{"execution":{"iopub.status.busy":"2021-07-03T09:52:00.083566Z","iopub.execute_input":"2021-07-03T09:52:00.084227Z","iopub.status.idle":"2021-07-03T09:52:00.372243Z","shell.execute_reply.started":"2021-07-03T09:52:00.084182Z","shell.execute_reply":"2021-07-03T09:52:00.371456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(img_arr, img_label,\n                                                    shuffle=True, stratify=img_label,\n                                                    train_size=0.9, random_state=42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-03T09:52:00.374118Z","iopub.execute_input":"2021-07-03T09:52:00.374421Z","iopub.status.idle":"2021-07-03T09:52:00.794331Z","shell.execute_reply.started":"2021-07-03T09:52:00.374385Z","shell.execute_reply":"2021-07-03T09:52:00.793347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del img_arr\ndel img_label","metadata":{"execution":{"iopub.status.busy":"2021-07-03T09:52:00.796043Z","iopub.execute_input":"2021-07-03T09:52:00.796349Z","iopub.status.idle":"2021-07-03T09:52:00.803419Z","shell.execute_reply.started":"2021-07-03T09:52:00.796312Z","shell.execute_reply":"2021-07-03T09:52:00.802328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_width = X_train.shape[1]\nimg_height = X_train.shape[2]\nimg_depth = X_train.shape[3]\nnum_classes = y_train.shape[1]","metadata":{"execution":{"iopub.status.busy":"2021-07-03T09:52:00.80482Z","iopub.execute_input":"2021-07-03T09:52:00.80513Z","iopub.status.idle":"2021-07-03T09:52:00.815271Z","shell.execute_reply.started":"2021-07-03T09:52:00.805095Z","shell.execute_reply":"2021-07-03T09:52:00.81433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.applications.MobileNetV2()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T09:52:17.627353Z","iopub.execute_input":"2021-07-03T09:52:17.627669Z","iopub.status.idle":"2021-07-03T09:52:22.996284Z","shell.execute_reply.started":"2021-07-03T09:52:17.627637Z","shell.execute_reply":"2021-07-03T09:52:22.995457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T09:52:22.99802Z","iopub.execute_input":"2021-07-03T09:52:22.998319Z","iopub.status.idle":"2021-07-03T09:52:23.058826Z","shell.execute_reply.started":"2021-07-03T09:52:22.998281Z","shell.execute_reply":"2021-07-03T09:52:23.057952Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-07-03T09:55:26.885335Z","iopub.execute_input":"2021-07-03T09:55:26.88563Z","iopub.status.idle":"2021-07-03T09:55:26.891533Z","shell.execute_reply.started":"2021-07-03T09:55:26.8856Z","shell.execute_reply":"2021-07-03T09:55:26.890635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobile_net = MobileNet(\n    input_shape = (img_width, img_height, img_depth),\n    include_top = False,\n    weights = \"imagenet\",\n    classes = num_classes\n)\n\nx = mobile_net.layers[-14].output\nglobal_pool = GlobalMaxPool2D(name=\"global_pool\")(x)\nout = Dense(num_classes, activation=\"softmax\", name=\"out_layer\")(global_pool)\n\nmodel = Model(inputs=mobile_net.input, outputs=out)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model, show_shapes=True, show_layer_names=True, expand_nested=True, dpi=50, to_file='mobilenet.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in model.layers[:15]:\n    layer.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    shear_range=0.15,\n    zoom_range=0.15,\n    horizontal_flip=True,\n    zca_whitening=False,\n)\ntrain_datagen.fit(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nI used two callbacks one is `early stopping` for avoiding overfitting training data\nand other `ReduceLROnPlateau` for learning rate.\n\"\"\"\nearly_stopping = EarlyStopping(\n    monitor='val_accuracy',\n    min_delta=0.00008,\n    patience=11,\n    verbose=1,\n    restore_best_weights=True,\n)\n\nlr_scheduler = ReduceLROnPlateau(\n    monitor='val_accuracy',\n    min_delta=0.0001,\n    factor=0.25,\n    patience=4,\n    min_lr=1e-7,\n    verbose=1,\n)\n\ncallbacks = [\n    early_stopping,\n    lr_scheduler,\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 25\nepochs = 40\n\noptims = [\n    optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n    optimizers.Adam(0.01),\n]\n\nmodel.compile(\n        loss='categorical_crossentropy',\n        optimizer=optims[1],\n        metrics=['accuracy']\n)\n\nhistory = model.fit_generator(\n    train_datagen.flow(X_train, y_train, batch_size=batch_size),\n    validation_data=(X_test, y_test),\n    steps_per_epoch=len(X_train) / batch_size,\n    epochs=epochs,\n    callbacks=callbacks,\n    use_multiprocessing=True\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_yaml = model.to_yaml()\nwith open(\"model_mobelnet.yaml\", \"w\") as yaml_file:\n    yaml_file.write(model_yaml)\n    \nmodel.save(\"model_moblenet.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set()\nfig = pyplot.figure(0, (12, 4))\n\nax = pyplot.subplot(1, 2, 1)\nsns.lineplot(history.epoch, history.history['accuracy'], label='train')\nsns.lineplot(history.epoch, history.history['val_accuracy'], label='valid')\npyplot.title('Accuracy')\npyplot.tight_layout()\n\nax = pyplot.subplot(1, 2, 2)\nsns.lineplot(history.epoch, history.history['loss'], label='train')\nsns.lineplot(history.epoch, history.history['val_loss'], label='valid')\npyplot.title('Loss')\npyplot.tight_layout()\n\npyplot.savefig('epoch_history_mobilenet.png')\npyplot.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_to_text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_to_label = dict((v,k) for k,v in label_to_text.items())\ntext_to_label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yhat_test = np.argmax(model.predict(X_test), axis=1)\nytest_ = np.argmax(y_test, axis=1)\n\nscikitplot.metrics.plot_confusion_matrix(ytest_, yhat_test, figsize=(7,7))\npyplot.savefig(\"confusion_matrix_mobilenet.png\")\n\ntest_accu = np.sum(ytest_ == yhat_test) / len(ytest_) * 100\nprint(f\"test accuracy: {round(test_accu, 4)} %\\n\\n\")\n\nprint(classification_report(ytest_, yhat_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The confusion matrix clearly shows that our model is doing good job on the class `happy` but it's performance is not that good on other classes. One of the reason for this could be the fact that these classes have less data as compared to `happy`.","metadata":{}},{"cell_type":"code","source":"np.random.seed(42)\nfear_imgs = np.random.choice(np.where(y_test[:, text_to_label[\"fear\"]]==1)[0], size=9, replace=False)\nangry_imgs = np.random.choice(np.where(y_test[:, text_to_label[\"Angry\"]]==1)[0], size=9, replace=False)\n\nfig = pyplot.figure(1, (18, 4))\n\nfor i, (fear_idx, angry_idx) in enumerate(zip(fear_imgs, angry_imgs)):\n        sample_img = X_test[fear_idx,:,:,:]\n        sample_img = sample_img.reshape(1,*sample_img.shape)\n        pred = label_to_text[np.argmax(model.predict(sample_img), axis=1)[0]]\n\n        ax = pyplot.subplot(2, 9, i+1)\n        ax.imshow(sample_img[0,:,:,0], cmap='gray')\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_title(f\"t:fear, p:{pred}\")\n\n        sample_img = X_test[angry_idx,:,:,:]\n        sample_img = sample_img.reshape(1,*sample_img.shape)\n        pred = label_to_text[np.argmax(model.predict(sample_img), axis=1)[0]]\n\n        ax = pyplot.subplot(2, 9, i+10)\n        ax.imshow(sample_img[0,:,:,0], cmap='gray')\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_title(f\"t:angry, p:{pred}\")\n\n        pyplot.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One of the reason for such low accuracy is the data quality. Below I have shown all the miss-classified images. Many of them doesn't belong to their true class but are actually looking more likely to the predicted class.","metadata":{}},{"cell_type":"code","source":"def plot_miss_classified(emotion):\n    miss_happy_indices = np.where((ytest_ != yhat_test) & (ytest_==text_to_label[emotion]))[0]\n    print(f\"total {len(miss_happy_indices)} miss labels out of {len(np.where(ytest_==text_to_label[emotion])[0])} for emotion {emotion}\")\n\n    cols = 15\n    rows = math.ceil(len(miss_happy_indices) / cols)\n    fig = pyplot.figure(1, (20, rows * 2))\n\n    for i,idx in enumerate(miss_happy_indices):\n        sample_img = X_test[idx,:,:,:]\n        sample_img = sample_img.reshape(1,*sample_img.shape)\n        pred = label_to_text[np.argmax(model.predict(sample_img), axis=1)[0]]\n\n        ax = pyplot.subplot(rows,cols,i+1)\n        ax.imshow(sample_img[0,:,:,0], cmap='gray')\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_title(f\"p:{pred}\")    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_miss_classified(emotion=\"Happy\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we see most of these are classified as `fear` the reason for that is that most of the fear mouths are opened as we see earlier and many of these mouths are opened like that.","metadata":{}},{"cell_type":"code","source":"plot_miss_classified(emotion=\"fear\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_miss_classified(emotion=\"Angry\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_miss_classified(emotion=\"Neutral\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}